{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7176593",
   "metadata": {},
   "source": [
    "# Deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd273cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils.motion_process import *\n",
    "import visualization.plot_3d_global as plot_3d\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from utils.motion_process import recover_from_ric \n",
    "from os.path import join as pjoin\n",
    "import numpy as np\n",
    "from utils.codebook import *\n",
    "from models.motion_dec import MotionDec\n",
    "from models.pg_tokenizer import PoseGuidedTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494a4b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def fixseed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2996d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixseed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e61df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "timestamp = now.strftime(\"%Y%m%d\")\n",
    "use_gpu = True\n",
    "use_custom_samples = True\n",
    "save_dir = f'./motion_editing_result/{timestamp}'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "test_sample_num = 20\n",
    "unit_length = 4\n",
    "\n",
    "sample_ids = []\n",
    "code_motions = []\n",
    "feats_motions = []\n",
    "int_indices = []\n",
    "motion_lens = []\n",
    "texts = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27edbe4b",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985f4d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.word_vectorizer import WordVectorizer\n",
    "w_vectorizer = WordVectorizer('./glove', 'our_vab')\n",
    "from dataset import dataset_TM_eval # \n",
    "\n",
    "if not use_custom_samples:\n",
    "    is_test = True\n",
    "    val_loader = dataset_TM_eval.DATALoader('t2m', is_test, 32, w_vectorizer, codebook_size=392,\n",
    "                                            use_keywords=True,\n",
    "                                            use_word_only=False)\n",
    "\n",
    "    val_loader_iter = dataset_TM_eval.cycle(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1914ea60",
   "metadata": {},
   "source": [
    "### Search sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bb5c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "split = 'test'\n",
    "with open(f'./dataset/HumanML3D/{split}.txt', 'r') as f:\n",
    "    split_file_names = f.read().splitlines()\n",
    "print(f\"number of {split} samples: {len(split_file_names)}\")\n",
    "\n",
    "example_text = ['a person lowers their arms']\n",
    "text_dir = './dataset/HumanML3D/texts'\n",
    "\n",
    "file_names = []\n",
    "retrieved_texts = []\n",
    "for file in os.listdir(text_dir):\n",
    "    if file.endswith('.txt'):\n",
    "        with open(f\"{text_dir}/{file}\", 'r') as f:\n",
    "            for idx, line in enumerate(f):\n",
    "                line = line.strip()\n",
    "                matched = any(phrase in line for phrase in example_text)\n",
    "                if matched:\n",
    "                    file_name = file.replace('.txt', '')\n",
    "                    if file_name in split_file_names:\n",
    "                        retrieved_texts.append(line.split('#')[0])\n",
    "                        file_names.append(file_name)\n",
    "                        print(\"name:\", file_name, \"text:\", line.split('#')[0])\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "searched_file_ids = [file_name for file_name in file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff794f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_dir = './dataset/HumanML3D/new_joint_vecs'\n",
    "motion_coord_dir = './dataset/HumanML3D/new_joints'\n",
    "code_dir = './dataset/HumanML3D/codes'\n",
    "text_dir = './dataset/HumanML3D/texts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f8a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.misc import kh2index\n",
    "target_file_list = ['013474']\n",
    "retrieved_texts = []\n",
    "use_ref_text = False\n",
    "for id in target_file_list:\n",
    "    with open(f\"{text_dir}/{id}.txt\", 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            sentence = line.strip().split('#')[0]\n",
    "            if use_ref_text:\n",
    "                if example_text[0] in sentence:\n",
    "                    retrieved_texts.append(sentence)\n",
    "                    break\n",
    "            else:\n",
    "                retrieved_texts.append(sentence)\n",
    "                break\n",
    "\n",
    "code_motions = []\n",
    "feats_motions = []\n",
    "int_indices = []\n",
    "motion_lens = []\n",
    "unit_length = 4\n",
    "print(retrieved_texts)\n",
    "\n",
    "for target_file_id in target_file_list:\n",
    "    m_feats = np.load(f\"{motion_dir}/{target_file_id}.npy\")\n",
    "    m_code = np.load(f\"{code_dir}/{target_file_id}.npy\")\n",
    "\n",
    "    n_seq, _ = m_code.shape\n",
    "    real_n_seq = (n_seq // unit_length) * unit_length\n",
    "\n",
    "    int_idx = kh2index(torch.from_numpy(m_code[:real_n_seq:unit_length]).float().unsqueeze(0)).squeeze(0)\n",
    "    p_length = int_idx.shape[0]\n",
    "    motion_lens.append(p_length)\n",
    "    int_indices.append(int_idx)\n",
    "    code_motions.append(m_code[:real_n_seq:unit_length])\n",
    "    feats_motions.append(m_feats[:real_n_seq])\n",
    "\n",
    "sample_ids = target_file_list\n",
    "texts = retrieved_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6134326",
   "metadata": {},
   "source": [
    "### Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677fb814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.misc import kh2index\n",
    "if not use_custom_samples:\n",
    "    code_motions = []\n",
    "    feats_motions = []\n",
    "    int_indices = []\n",
    "    motion_lens = []\n",
    "    \n",
    "    batch = next(val_loader_iter)\n",
    "    word_embeddings, pos_one_hots, clip_text, sent_len, pose, m_length, token, name, indices, keyword_embeddings, *_ = batch\n",
    "    \n",
    "    sample_ids = name[:test_sample_num]\n",
    "    texts = clip_text[:test_sample_num]\n",
    "\n",
    "    for i in range(test_sample_num):\n",
    "        idx = i\n",
    "        int_idx = kh2index(indices[idx:idx+1, :m_length[idx]:unit_length]).squeeze(0)\n",
    "        p_length = int_idx.shape[0]\n",
    "        motion_lens.append(p_length)\n",
    "        int_indices.append(int_idx)\n",
    "        code_motions.append(indices[idx, :m_length[idx]:unit_length])\n",
    "        feats_motions.append(pose[idx, :m_length[idx]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fedbdc",
   "metadata": {},
   "source": [
    "### Save Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55d7976",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fae2e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "draw_gt = True\n",
    "vis_save_dir = pjoin(save_dir, 'gt', 'gif')\n",
    "npy_pose_save_dir = pjoin(save_dir, 'gt', 'npy_pose')\n",
    "npy_coords_save_dir = pjoin(save_dir, 'gt', 'npy_coords')\n",
    "npy_codes_save_dir = pjoin(save_dir, 'gt', 'codes')\n",
    "texts_save_dir = pjoin(save_dir, 'gt', 'texts')\n",
    "\n",
    "print(\"Saving results to:\", save_dir)\n",
    "\n",
    "os.makedirs(vis_save_dir, exist_ok=True)\n",
    "os.makedirs(npy_pose_save_dir, exist_ok=True)\n",
    "os.makedirs(npy_coords_save_dir, exist_ok=True)\n",
    "os.makedirs(npy_codes_save_dir, exist_ok=True)\n",
    "os.makedirs(texts_save_dir, exist_ok=True)\n",
    "\n",
    "# ground truth pose\n",
    "for idx, id in tqdm(enumerate(sample_ids)):\n",
    "    print(f\"## id:{id} ##\")\n",
    "    pose = feats_motions[idx]\n",
    "    \n",
    "    if not use_custom_samples:\n",
    "        gt_denorm = val_loader.dataset.inv_transform(pose.cpu().numpy())\n",
    "    else:\n",
    "        gt_denorm = pose\n",
    "    np.save(f\"{npy_pose_save_dir}/{id}.npy\", gt_denorm)\n",
    "\n",
    "    gt_pose_xyz = recover_from_ric(torch.from_numpy(gt_denorm).float(), 22).numpy()\n",
    "    np.save(f\"{npy_coords_save_dir}/{id}.npy\", gt_pose_xyz)\n",
    "\n",
    "    code_ = code_motions[idx]\n",
    "    np.save(f\"{npy_codes_save_dir}/{id}.npy\", code_) \n",
    "\n",
    "    sentence = texts[idx]\n",
    "    with open(f\"{texts_save_dir}/{id}.txt\", 'w') as f:\n",
    "        f.write(sentence)\n",
    "\n",
    "    gt_pose_xyz = gt_pose_xyz[None, :]\n",
    "    gt_save_path = f\"{vis_save_dir}/{id}.gif\"\n",
    "    if draw_gt:\n",
    "        plot_3d.draw_to_batch(gt_pose_xyz, [sentence], [gt_save_path], footer_text='Ground Truth', footer_fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab85c1a",
   "metadata": {},
   "source": [
    "# Prepare Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f5b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9c57e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "editing_scenario = {\n",
    "    1: {\n",
    "        \"text\": \"the person put his hands on his knees.\",\n",
    "        \"scenario\": \"Bend both arms more deeply\"\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "'''editing_scenario = {\n",
    "    1: {\n",
    "        \"text\": \"the person put his hands on his knees.\",\n",
    "        \"scenario\": \"Bend both arms more deeply\"\n",
    "    },\n",
    "    2: {\n",
    "        \"text\": \"a person is walking forward\",\n",
    "        \"scenario\": \"Raise left hand at the end.\"\n",
    "    },\n",
    "    3: {\n",
    "        \"text\": \"this person bends forward as if to bow.\",\n",
    "        \"scenario\": \"Bring both hands closer together.\"\n",
    "    },\n",
    "    4: {\n",
    "        \"text\": \"a person waves their arms over their heads.\",\n",
    "        \"scenario\": \" Bend your knees more deeply\"\n",
    "    },\n",
    "    5: {\n",
    "        \"text\": \"a man stands and raises both of his arms overhead and then makes up and downwards movements.\",\n",
    "        \"scenario\": \"Bend both arms more deeply\"\n",
    "    }\n",
    "}'''\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f69047",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p_table1 = {0: 'L-knee angle',\n",
    " 1: 'R-knee angle',\n",
    " 2: 'L-elbow angle',\n",
    " 3: 'R-elbow angle',\n",
    " 4: 'L-elbow vs R-elbow distance',\n",
    " 5: 'L-hand vs R-hand distance',\n",
    " 6: 'L-knee vs R-knee distance',\n",
    " 7: 'L-foot vs R-foot distance',\n",
    " 8: 'L-hand vs L-shoulder distance',\n",
    " 9: 'L-hand vs R-shoulder distance',\n",
    " 10: 'R-hand vs R-shoulder distance',\n",
    " 11: 'R-hand vs L-shoulder distance',\n",
    " 12: 'L-hand vs R-elbow distance',\n",
    " 13: 'R-hand vs L-elbow distance',\n",
    " 14: 'L-hand vs L-knee distance',\n",
    " 15: 'L-hand vs R-knee distance',\n",
    " 16: 'R-hand vs R-knee distance',\n",
    " 17: 'R-hand vs L-knee distance',\n",
    " 18: 'L-hand vs L-foot distance',\n",
    " 19: 'L-hand vs R-foot distance',\n",
    " 20: 'R-hand vs R-foot distance',\n",
    " 21: 'R-hand vs L-foot distance',\n",
    " 22: 'L-hand vs R-hand relX',\n",
    " 23: 'neck vs pelvis relX',\n",
    " 24: 'L-hand vs L-shoulder relX',\n",
    " 25: 'R-hand vs R-shoulder relX',\n",
    " 26: 'L-foot vs L-hip relX',\n",
    " 27: 'R-foot vs R-hip relX',\n",
    " 28: 'L-shoulder vs R-shoulder relY',\n",
    " 29: 'L-elbow vs R-elbow relY',\n",
    " 30: 'L-hand vs R-hand relY',\n",
    " 31: 'L-ankle vs neck relY',\n",
    " 32: 'R-ankle vs neck relY',\n",
    " 33: 'L-knee vs R-knee relY',\n",
    " 34: 'L-hip vs L-knee relY',\n",
    " 35: 'R-hip vs R-knee relY',\n",
    " 36: 'L-hand vs L-shoulder relY',\n",
    " 37: 'R-hand vs R-shoulder relY',\n",
    " 38: 'L-foot vs L-hip relY',\n",
    " 39: 'R-foot vs R-hip relY',\n",
    " 40: 'L-wrist vs neck relY',\n",
    " 41: 'R-wrist vs neck relY',\n",
    " 42: 'L-hand vs L-hip relY',\n",
    " 43: 'R-hand vs R-hip relY',\n",
    " 44: 'L-shoulder vs R-shoulder relZ',\n",
    " 45: 'L-elbow vs R-elbow relZ',\n",
    " 46: 'L-hand vs R-hand relZ',\n",
    " 47: 'L-knee vs R-knee relZ',\n",
    " 48: 'neck vs pelvis relZ',\n",
    " 49: 'L-hand vs torso relZ',\n",
    " 50: 'R-hand vs torso relZ',\n",
    " 51: 'L-foot vs torso relZ',\n",
    " 52: 'R-foot vs torso relZ',\n",
    " 53: 'L-hip vs L-knee relV',\n",
    " 54: 'R-hip vs R-knee relV',\n",
    " 55: 'L-knee vs L-ankle relV',\n",
    " 56: 'R-knee vs R-ankle relV',\n",
    " 57: 'L-shoulder vs L-elbow relV',\n",
    " 58: 'R-shoulder vs R-elbow relV',\n",
    " 59: 'L-elbow vs L-wrist relV',\n",
    " 60: 'R-elbow vs R-wrist relV',\n",
    " 61: 'pelvis vs L-shoulder relV',\n",
    " 62: 'pelvis vs R-shoulder relV',\n",
    " 63: 'pelvis vs neck relV',\n",
    " 64: 'L-hand vs R-hand relV',\n",
    " 65: 'L-foot vs R-foot relV',\n",
    " 66: 'L-knee ground',\n",
    " 67: 'R-knee ground',\n",
    " 68: 'L-foot ground',\n",
    " 69: 'R-foot ground'}\n",
    "p_table2 = {0: 'L-knee angle 0 (bent to almost 10 degrees)',\n",
    " 1: 'L-knee angle 1 (bent to almost 20 degrees)',\n",
    " 2: 'L-knee angle 2 (bent to almost 30 degrees)',\n",
    " 3: 'L-knee angle 3 (bent to almost 40 degrees)',\n",
    " 4: 'L-knee angle 4 (bent to almost 50 degrees)',\n",
    " 5: 'L-knee angle 5 (bent to almost 60 degrees)',\n",
    " 6: 'L-knee angle 6 (bent to almost 70 degrees)',\n",
    " 7: 'L-knee angle 7 (bent to almost 80 degrees)',\n",
    " 8: 'L-knee angle 8 (bent to almost 90 degrees)',\n",
    " 9: 'L-knee angle 9 (bent to almost 100 degrees)',\n",
    " 10: 'L-knee angle 10 (bent to almost 110 degrees)',\n",
    " 11: 'L-knee angle 11 (bent to almost 120 degrees)',\n",
    " 12: 'L-knee angle 12 (bent to almost 130 degrees)',\n",
    " 13: 'L-knee angle 13 (bent to almost 140 degrees)',\n",
    " 14: 'L-knee angle 14 (bent to almost 150 degrees)',\n",
    " 15: 'L-knee angle 15 (bent to almost 160 degrees)',\n",
    " 16: 'L-knee angle 16 (bent to almost 170 degrees)',\n",
    " 17: 'L-knee angle 17 (straight)',\n",
    " 18: 'R-knee angle 0 (bent to almost 10 degrees)',\n",
    " 19: 'R-knee angle 1 (bent to almost 20 degrees)',\n",
    " 20: 'R-knee angle 2 (bent to almost 30 degrees)',\n",
    " 21: 'R-knee angle 3 (bent to almost 40 degrees)',\n",
    " 22: 'R-knee angle 4 (bent to almost 50 degrees)',\n",
    " 23: 'R-knee angle 5 (bent to almost 60 degrees)',\n",
    " 24: 'R-knee angle 6 (bent to almost 70 degrees)',\n",
    " 25: 'R-knee angle 7 (bent to almost 80 degrees)',\n",
    " 26: 'R-knee angle 8 (bent to almost 90 degrees)',\n",
    " 27: 'R-knee angle 9 (bent to almost 100 degrees)',\n",
    " 28: 'R-knee angle 10 (bent to almost 110 degrees)',\n",
    " 29: 'R-knee angle 11 (bent to almost 120 degrees)',\n",
    " 30: 'R-knee angle 12 (bent to almost 130 degrees)',\n",
    " 31: 'R-knee angle 13 (bent to almost 140 degrees)',\n",
    " 32: 'R-knee angle 14 (bent to almost 150 degrees)',\n",
    " 33: 'R-knee angle 15 (bent to almost 160 degrees)',\n",
    " 34: 'R-knee angle 16 (bent to almost 170 degrees)',\n",
    " 35: 'R-knee angle 17 (straight)',\n",
    " 36: 'L-elbow angle 0 (bent to almost 10 degrees)',\n",
    " 37: 'L-elbow angle 1 (bent to almost 20 degrees)',\n",
    " 38: 'L-elbow angle 2 (bent to almost 30 degrees)',\n",
    " 39: 'L-elbow angle 3 (bent to almost 40 degrees)',\n",
    " 40: 'L-elbow angle 4 (bent to almost 50 degrees)',\n",
    " 41: 'L-elbow angle 5 (bent to almost 60 degrees)',\n",
    " 42: 'L-elbow angle 6 (bent to almost 70 degrees)',\n",
    " 43: 'L-elbow angle 7 (bent to almost 80 degrees)',\n",
    " 44: 'L-elbow angle 8 (bent to almost 90 degrees)',\n",
    " 45: 'L-elbow angle 9 (bent to almost 100 degrees)',\n",
    " 46: 'L-elbow angle 10 (bent to almost 110 degrees)',\n",
    " 47: 'L-elbow angle 11 (bent to almost 120 degrees)',\n",
    " 48: 'L-elbow angle 12 (bent to almost 130 degrees)',\n",
    " 49: 'L-elbow angle 13 (bent to almost 140 degrees)',\n",
    " 50: 'L-elbow angle 14 (bent to almost 150 degrees)',\n",
    " 51: 'L-elbow angle 15 (bent to almost 160 degrees)',\n",
    " 52: 'L-elbow angle 16 (bent to almost 170 degrees)',\n",
    " 53: 'L-elbow angle 17 (straight)',\n",
    " 54: 'R-elbow angle 0 (bent to almost 10 degrees)',\n",
    " 55: 'R-elbow angle 1 (bent to almost 20 degrees)',\n",
    " 56: 'R-elbow angle 2 (bent to almost 30 degrees)',\n",
    " 57: 'R-elbow angle 3 (bent to almost 40 degrees)',\n",
    " 58: 'R-elbow angle 4 (bent to almost 50 degrees)',\n",
    " 59: 'R-elbow angle 5 (bent to almost 60 degrees)',\n",
    " 60: 'R-elbow angle 6 (bent to almost 70 degrees)',\n",
    " 61: 'R-elbow angle 7 (bent to almost 80 degrees)',\n",
    " 62: 'R-elbow angle 8 (bent to almost 90 degrees)',\n",
    " 63: 'R-elbow angle 9 (bent to almost 100 degrees)',\n",
    " 64: 'R-elbow angle 10 (bent to almost 110 degrees)',\n",
    " 65: 'R-elbow angle 11 (bent to almost 120 degrees)',\n",
    " 66: 'R-elbow angle 12 (bent to almost 130 degrees)',\n",
    " 67: 'R-elbow angle 13 (bent to almost 140 degrees)',\n",
    " 68: 'R-elbow angle 14 (bent to almost 150 degrees)',\n",
    " 69: 'R-elbow angle 15 (bent to almost 160 degrees)',\n",
    " 70: 'R-elbow angle 16 (bent to almost 170 degrees)',\n",
    " 71: 'R-elbow angle 17 (straight)',\n",
    " 72: 'L-elbow vs R-elbow distance 0 (very close)',\n",
    " 73: 'L-elbow vs R-elbow distance 1 (slightly close)',\n",
    " 74: 'L-elbow vs R-elbow distance 2 (close)',\n",
    " 75: 'L-elbow vs R-elbow distance 3 (almost shoulder width apart)',\n",
    " 76: 'L-elbow vs R-elbow distance 4 (shoulder width apart)',\n",
    " 77: 'L-elbow vs R-elbow distance 5 (almost spread)',\n",
    " 78: 'L-elbow vs R-elbow distance 6 (spread)',\n",
    " 79: 'L-elbow vs R-elbow distance 7 (slightly wide)',\n",
    " 80: 'L-elbow vs R-elbow distance 8 (wide)',\n",
    " 81: 'L-elbow vs R-elbow distance 9 (very wide)',\n",
    " 82: 'L-hand vs R-hand distance 0 (very close)',\n",
    " 83: 'L-hand vs R-hand distance 1 (slightly close)',\n",
    " 84: 'L-hand vs R-hand distance 2 (close)',\n",
    " 85: 'L-hand vs R-hand distance 3 (almost shoulder width apart)',\n",
    " 86: 'L-hand vs R-hand distance 4 (shoulder width apart)',\n",
    " 87: 'L-hand vs R-hand distance 5 (almost spread)',\n",
    " 88: 'L-hand vs R-hand distance 6 (spread)',\n",
    " 89: 'L-hand vs R-hand distance 7 (slightly wide)',\n",
    " 90: 'L-hand vs R-hand distance 8 (wide)',\n",
    " 91: 'L-hand vs R-hand distance 9 (very wide)',\n",
    " 92: 'L-knee vs R-knee distance 0 (very close)',\n",
    " 93: 'L-knee vs R-knee distance 1 (slightly close)',\n",
    " 94: 'L-knee vs R-knee distance 2 (close)',\n",
    " 95: 'L-knee vs R-knee distance 3 (almost shoulder width apart)',\n",
    " 96: 'L-knee vs R-knee distance 4 (shoulder width apart)',\n",
    " 97: 'L-knee vs R-knee distance 5 (almost spread)',\n",
    " 98: 'L-knee vs R-knee distance 6 (spread)',\n",
    " 99: 'L-knee vs R-knee distance 7 (slightly wide)',\n",
    " 100: 'L-knee vs R-knee distance 8 (wide)',\n",
    " 101: 'L-knee vs R-knee distance 9 (very wide)',\n",
    " 102: 'L-foot vs R-foot distance 0 (very close)',\n",
    " 103: 'L-foot vs R-foot distance 1 (slightly close)',\n",
    " 104: 'L-foot vs R-foot distance 2 (close)',\n",
    " 105: 'L-foot vs R-foot distance 3 (almost shoulder width apart)',\n",
    " 106: 'L-foot vs R-foot distance 4 (shoulder width apart)',\n",
    " 107: 'L-foot vs R-foot distance 5 (almost spread)',\n",
    " 108: 'L-foot vs R-foot distance 6 (spread)',\n",
    " 109: 'L-foot vs R-foot distance 7 (slightly wide)',\n",
    " 110: 'L-foot vs R-foot distance 8 (wide)',\n",
    " 111: 'L-foot vs R-foot distance 9 (very wide)',\n",
    " 112: 'L-hand vs L-shoulder distance 0 (very close)',\n",
    " 113: 'L-hand vs L-shoulder distance 1 (slightly close)',\n",
    " 114: 'L-hand vs L-shoulder distance 2 (close)',\n",
    " 115: 'L-hand vs L-shoulder distance 3 (almost shoulder width apart)',\n",
    " 116: 'L-hand vs L-shoulder distance 4 (shoulder width apart)',\n",
    " 117: 'L-hand vs L-shoulder distance 5 (almost spread)',\n",
    " 118: 'L-hand vs L-shoulder distance 6 (spread)',\n",
    " 119: 'L-hand vs L-shoulder distance 7 (slightly wide)',\n",
    " 120: 'L-hand vs L-shoulder distance 8 (wide)',\n",
    " 121: 'L-hand vs L-shoulder distance 9 (very wide)',\n",
    " 122: 'L-hand vs R-shoulder distance 0 (very close)',\n",
    " 123: 'L-hand vs R-shoulder distance 1 (slightly close)',\n",
    " 124: 'L-hand vs R-shoulder distance 2 (close)',\n",
    " 125: 'L-hand vs R-shoulder distance 3 (almost shoulder width apart)',\n",
    " 126: 'L-hand vs R-shoulder distance 4 (shoulder width apart)',\n",
    " 127: 'L-hand vs R-shoulder distance 5 (almost spread)',\n",
    " 128: 'L-hand vs R-shoulder distance 6 (spread)',\n",
    " 129: 'L-hand vs R-shoulder distance 7 (slightly wide)',\n",
    " 130: 'L-hand vs R-shoulder distance 8 (wide)',\n",
    " 131: 'L-hand vs R-shoulder distance 9 (very wide)',\n",
    " 132: 'R-hand vs R-shoulder distance 0 (very close)',\n",
    " 133: 'R-hand vs R-shoulder distance 1 (slightly close)',\n",
    " 134: 'R-hand vs R-shoulder distance 2 (close)',\n",
    " 135: 'R-hand vs R-shoulder distance 3 (almost shoulder width apart)',\n",
    " 136: 'R-hand vs R-shoulder distance 4 (shoulder width apart)',\n",
    " 137: 'R-hand vs R-shoulder distance 5 (almost spread)',\n",
    " 138: 'R-hand vs R-shoulder distance 6 (spread)',\n",
    " 139: 'R-hand vs R-shoulder distance 7 (slightly wide)',\n",
    " 140: 'R-hand vs R-shoulder distance 8 (wide)',\n",
    " 141: 'R-hand vs R-shoulder distance 9 (very wide)',\n",
    " 142: 'R-hand vs L-shoulder distance 0 (very close)',\n",
    " 143: 'R-hand vs L-shoulder distance 1 (slightly close)',\n",
    " 144: 'R-hand vs L-shoulder distance 2 (close)',\n",
    " 145: 'R-hand vs L-shoulder distance 3 (almost shoulder width apart)',\n",
    " 146: 'R-hand vs L-shoulder distance 4 (shoulder width apart)',\n",
    " 147: 'R-hand vs L-shoulder distance 5 (almost spread)',\n",
    " 148: 'R-hand vs L-shoulder distance 6 (spread)',\n",
    " 149: 'R-hand vs L-shoulder distance 7 (slightly wide)',\n",
    " 150: 'R-hand vs L-shoulder distance 8 (wide)',\n",
    " 151: 'R-hand vs L-shoulder distance 9 (very wide)',\n",
    " 152: 'L-hand vs R-elbow distance 0 (very close)',\n",
    " 153: 'L-hand vs R-elbow distance 1 (slightly close)',\n",
    " 154: 'L-hand vs R-elbow distance 2 (close)',\n",
    " 155: 'L-hand vs R-elbow distance 3 (almost shoulder width apart)',\n",
    " 156: 'L-hand vs R-elbow distance 4 (shoulder width apart)',\n",
    " 157: 'L-hand vs R-elbow distance 5 (almost spread)',\n",
    " 158: 'L-hand vs R-elbow distance 6 (spread)',\n",
    " 159: 'L-hand vs R-elbow distance 7 (slightly wide)',\n",
    " 160: 'L-hand vs R-elbow distance 8 (wide)',\n",
    " 161: 'L-hand vs R-elbow distance 9 (very wide)',\n",
    " 162: 'R-hand vs L-elbow distance 0 (very close)',\n",
    " 163: 'R-hand vs L-elbow distance 1 (slightly close)',\n",
    " 164: 'R-hand vs L-elbow distance 2 (close)',\n",
    " 165: 'R-hand vs L-elbow distance 3 (almost shoulder width apart)',\n",
    " 166: 'R-hand vs L-elbow distance 4 (shoulder width apart)',\n",
    " 167: 'R-hand vs L-elbow distance 5 (almost spread)',\n",
    " 168: 'R-hand vs L-elbow distance 6 (spread)',\n",
    " 169: 'R-hand vs L-elbow distance 7 (slightly wide)',\n",
    " 170: 'R-hand vs L-elbow distance 8 (wide)',\n",
    " 171: 'R-hand vs L-elbow distance 9 (very wide)',\n",
    " 172: 'L-hand vs L-knee distance 0 (very close)',\n",
    " 173: 'L-hand vs L-knee distance 1 (slightly close)',\n",
    " 174: 'L-hand vs L-knee distance 2 (close)',\n",
    " 175: 'L-hand vs L-knee distance 3 (almost shoulder width apart)',\n",
    " 176: 'L-hand vs L-knee distance 4 (shoulder width apart)',\n",
    " 177: 'L-hand vs L-knee distance 5 (almost spread)',\n",
    " 178: 'L-hand vs L-knee distance 6 (spread)',\n",
    " 179: 'L-hand vs L-knee distance 7 (slightly wide)',\n",
    " 180: 'L-hand vs L-knee distance 8 (wide)',\n",
    " 181: 'L-hand vs L-knee distance 9 (very wide)',\n",
    " 182: 'L-hand vs R-knee distance 0 (very close)',\n",
    " 183: 'L-hand vs R-knee distance 1 (slightly close)',\n",
    " 184: 'L-hand vs R-knee distance 2 (close)',\n",
    " 185: 'L-hand vs R-knee distance 3 (almost shoulder width apart)',\n",
    " 186: 'L-hand vs R-knee distance 4 (shoulder width apart)',\n",
    " 187: 'L-hand vs R-knee distance 5 (almost spread)',\n",
    " 188: 'L-hand vs R-knee distance 6 (spread)',\n",
    " 189: 'L-hand vs R-knee distance 7 (slightly wide)',\n",
    " 190: 'L-hand vs R-knee distance 8 (wide)',\n",
    " 191: 'L-hand vs R-knee distance 9 (very wide)',\n",
    " 192: 'R-hand vs R-knee distance 0 (very close)',\n",
    " 193: 'R-hand vs R-knee distance 1 (slightly close)',\n",
    " 194: 'R-hand vs R-knee distance 2 (close)',\n",
    " 195: 'R-hand vs R-knee distance 3 (almost shoulder width apart)',\n",
    " 196: 'R-hand vs R-knee distance 4 (shoulder width apart)',\n",
    " 197: 'R-hand vs R-knee distance 5 (almost spread)',\n",
    " 198: 'R-hand vs R-knee distance 6 (spread)',\n",
    " 199: 'R-hand vs R-knee distance 7 (slightly wide)',\n",
    " 200: 'R-hand vs R-knee distance 8 (wide)',\n",
    " 201: 'R-hand vs R-knee distance 9 (very wide)',\n",
    " 202: 'R-hand vs L-knee distance 0 (very close)',\n",
    " 203: 'R-hand vs L-knee distance 1 (slightly close)',\n",
    " 204: 'R-hand vs L-knee distance 2 (close)',\n",
    " 205: 'R-hand vs L-knee distance 3 (almost shoulder width apart)',\n",
    " 206: 'R-hand vs L-knee distance 4 (shoulder width apart)',\n",
    " 207: 'R-hand vs L-knee distance 5 (almost spread)',\n",
    " 208: 'R-hand vs L-knee distance 6 (spread)',\n",
    " 209: 'R-hand vs L-knee distance 7 (slightly wide)',\n",
    " 210: 'R-hand vs L-knee distance 8 (wide)',\n",
    " 211: 'R-hand vs L-knee distance 9 (very wide)',\n",
    " 212: 'L-hand vs L-foot distance 0 (very close)',\n",
    " 213: 'L-hand vs L-foot distance 1 (slightly close)',\n",
    " 214: 'L-hand vs L-foot distance 2 (close)',\n",
    " 215: 'L-hand vs L-foot distance 3 (almost shoulder width apart)',\n",
    " 216: 'L-hand vs L-foot distance 4 (shoulder width apart)',\n",
    " 217: 'L-hand vs L-foot distance 5 (almost spread)',\n",
    " 218: 'L-hand vs L-foot distance 6 (spread)',\n",
    " 219: 'L-hand vs L-foot distance 7 (slightly wide)',\n",
    " 220: 'L-hand vs L-foot distance 8 (wide)',\n",
    " 221: 'L-hand vs L-foot distance 9 (very wide)',\n",
    " 222: 'L-hand vs R-foot distance 0 (very close)',\n",
    " 223: 'L-hand vs R-foot distance 1 (slightly close)',\n",
    " 224: 'L-hand vs R-foot distance 2 (close)',\n",
    " 225: 'L-hand vs R-foot distance 3 (almost shoulder width apart)',\n",
    " 226: 'L-hand vs R-foot distance 4 (shoulder width apart)',\n",
    " 227: 'L-hand vs R-foot distance 5 (almost spread)',\n",
    " 228: 'L-hand vs R-foot distance 6 (spread)',\n",
    " 229: 'L-hand vs R-foot distance 7 (slightly wide)',\n",
    " 230: 'L-hand vs R-foot distance 8 (wide)',\n",
    " 231: 'L-hand vs R-foot distance 9 (very wide)',\n",
    " 232: 'R-hand vs R-foot distance 0 (very close)',\n",
    " 233: 'R-hand vs R-foot distance 1 (slightly close)',\n",
    " 234: 'R-hand vs R-foot distance 2 (close)',\n",
    " 235: 'R-hand vs R-foot distance 3 (almost shoulder width apart)',\n",
    " 236: 'R-hand vs R-foot distance 4 (shoulder width apart)',\n",
    " 237: 'R-hand vs R-foot distance 5 (almost spread)',\n",
    " 238: 'R-hand vs R-foot distance 6 (spread)',\n",
    " 239: 'R-hand vs R-foot distance 7 (slightly wide)',\n",
    " 240: 'R-hand vs R-foot distance 8 (wide)',\n",
    " 241: 'R-hand vs R-foot distance 9 (very wide)',\n",
    " 242: 'R-hand vs L-foot distance 0 (very close)',\n",
    " 243: 'R-hand vs L-foot distance 1 (slightly close)',\n",
    " 244: 'R-hand vs L-foot distance 2 (close)',\n",
    " 245: 'R-hand vs L-foot distance 3 (almost shoulder width apart)',\n",
    " 246: 'R-hand vs L-foot distance 4 (shoulder width apart)',\n",
    " 247: 'R-hand vs L-foot distance 5 (almost spread)',\n",
    " 248: 'R-hand vs L-foot distance 6 (spread)',\n",
    " 249: 'R-hand vs L-foot distance 7 (slightly wide)',\n",
    " 250: 'R-hand vs L-foot distance 8 (wide)',\n",
    " 251: 'R-hand vs L-foot distance 9 (very wide)',\n",
    " 252: 'L-hand vs R-hand relX at the right of',\n",
    " 253: 'L-hand vs R-hand relX x-ignored',\n",
    " 254: 'L-hand vs R-hand relX at the left of',\n",
    " 255: 'neck vs pelvis relX at the right of',\n",
    " 256: 'neck vs pelvis relX x-ignored',\n",
    " 257: 'neck vs pelvis relX at the left of',\n",
    " 258: 'L-hand vs L-shoulder relX at the right of',\n",
    " 259: 'L-hand vs L-shoulder relX x-ignored',\n",
    " 260: 'L-hand vs L-shoulder relX at the left of',\n",
    " 261: 'R-hand vs R-shoulder relX at the right of',\n",
    " 262: 'R-hand vs R-shoulder relX x-ignored',\n",
    " 263: 'R-hand vs R-shoulder relX at the left of',\n",
    " 264: 'L-foot vs L-hip relX at the right of',\n",
    " 265: 'L-foot vs L-hip relX x-ignored',\n",
    " 266: 'L-foot vs L-hip relX at the left of',\n",
    " 267: 'R-foot vs R-hip relX at the right of',\n",
    " 268: 'R-foot vs R-hip relX x-ignored',\n",
    " 269: 'R-foot vs R-hip relX at the left of',\n",
    " 270: 'L-shoulder vs R-shoulder relY below',\n",
    " 271: 'L-shoulder vs R-shoulder relY y-ignored',\n",
    " 272: 'L-shoulder vs R-shoulder relY above',\n",
    " 273: 'L-elbow vs R-elbow relY below',\n",
    " 274: 'L-elbow vs R-elbow relY y-ignored',\n",
    " 275: 'L-elbow vs R-elbow relY above',\n",
    " 276: 'L-hand vs R-hand relY below',\n",
    " 277: 'L-hand vs R-hand relY y-ignored',\n",
    " 278: 'L-hand vs R-hand relY above',\n",
    " 279: 'L-ankle vs neck relY below',\n",
    " 280: 'L-ankle vs neck relY y-ignored',\n",
    " 281: 'L-ankle vs neck relY above',\n",
    " 282: 'R-ankle vs neck relY below',\n",
    " 283: 'R-ankle vs neck relY y-ignored',\n",
    " 284: 'R-ankle vs neck relY above',\n",
    " 285: 'L-knee vs R-knee relY below',\n",
    " 286: 'L-knee vs R-knee relY y-ignored',\n",
    " 287: 'L-knee vs R-knee relY above',\n",
    " 288: 'L-hip vs L-knee relY below',\n",
    " 289: 'L-hip vs L-knee relY y-ignored',\n",
    " 290: 'L-hip vs L-knee relY above',\n",
    " 291: 'R-hip vs R-knee relY below',\n",
    " 292: 'R-hip vs R-knee relY y-ignored',\n",
    " 293: 'R-hip vs R-knee relY above',\n",
    " 294: 'L-hand vs L-shoulder relY below',\n",
    " 295: 'L-hand vs L-shoulder relY y-ignored',\n",
    " 296: 'L-hand vs L-shoulder relY above',\n",
    " 297: 'R-hand vs R-shoulder relY below',\n",
    " 298: 'R-hand vs R-shoulder relY y-ignored',\n",
    " 299: 'R-hand vs R-shoulder relY above',\n",
    " 300: 'L-foot vs L-hip relY below',\n",
    " 301: 'L-foot vs L-hip relY y-ignored',\n",
    " 302: 'L-foot vs L-hip relY above',\n",
    " 303: 'R-foot vs R-hip relY below',\n",
    " 304: 'R-foot vs R-hip relY y-ignored',\n",
    " 305: 'R-foot vs R-hip relY above',\n",
    " 306: 'L-wrist vs neck relY below',\n",
    " 307: 'L-wrist vs neck relY y-ignored',\n",
    " 308: 'L-wrist vs neck relY above',\n",
    " 309: 'R-wrist vs neck relY below',\n",
    " 310: 'R-wrist vs neck relY y-ignored',\n",
    " 311: 'R-wrist vs neck relY above',\n",
    " 312: 'L-hand vs L-hip relY below',\n",
    " 313: 'L-hand vs L-hip relY y-ignored',\n",
    " 314: 'L-hand vs L-hip relY above',\n",
    " 315: 'R-hand vs R-hip relY below',\n",
    " 316: 'R-hand vs R-hip relY y-ignored',\n",
    " 317: 'R-hand vs R-hip relY above',\n",
    " 318: 'L-shoulder vs R-shoulder relZ behind',\n",
    " 319: 'L-shoulder vs R-shoulder relZ z-ignored',\n",
    " 320: 'L-shoulder vs R-shoulder relZ in front of',\n",
    " 321: 'L-elbow vs R-elbow relZ behind',\n",
    " 322: 'L-elbow vs R-elbow relZ z-ignored',\n",
    " 323: 'L-elbow vs R-elbow relZ in front of',\n",
    " 324: 'L-hand vs R-hand relZ behind',\n",
    " 325: 'L-hand vs R-hand relZ z-ignored',\n",
    " 326: 'L-hand vs R-hand relZ in front of',\n",
    " 327: 'L-knee vs R-knee relZ behind',\n",
    " 328: 'L-knee vs R-knee relZ z-ignored',\n",
    " 329: 'L-knee vs R-knee relZ in front of',\n",
    " 330: 'neck vs pelvis relZ behind',\n",
    " 331: 'neck vs pelvis relZ z-ignored',\n",
    " 332: 'neck vs pelvis relZ in front of',\n",
    " 333: 'L-hand vs torso relZ behind',\n",
    " 334: 'L-hand vs torso relZ z-ignored',\n",
    " 335: 'L-hand vs torso relZ in front of',\n",
    " 336: 'R-hand vs torso relZ behind',\n",
    " 337: 'R-hand vs torso relZ z-ignored',\n",
    " 338: 'R-hand vs torso relZ in front of',\n",
    " 339: 'L-foot vs torso relZ behind',\n",
    " 340: 'L-foot vs torso relZ z-ignored',\n",
    " 341: 'L-foot vs torso relZ in front of',\n",
    " 342: 'R-foot vs torso relZ behind',\n",
    " 343: 'R-foot vs torso relZ z-ignored',\n",
    " 344: 'R-foot vs torso relZ in front of',\n",
    " 345: 'L-hip vs L-knee relV vertical',\n",
    " 346: 'L-hip vs L-knee relV ignored',\n",
    " 347: 'L-hip vs L-knee relV horizontal',\n",
    " 348: 'R-hip vs R-knee relV vertical',\n",
    " 349: 'R-hip vs R-knee relV ignored',\n",
    " 350: 'R-hip vs R-knee relV horizontal',\n",
    " 351: 'L-knee vs L-ankle relV vertical',\n",
    " 352: 'L-knee vs L-ankle relV ignored',\n",
    " 353: 'L-knee vs L-ankle relV horizontal',\n",
    " 354: 'R-knee vs R-ankle relV vertical',\n",
    " 355: 'R-knee vs R-ankle relV ignored',\n",
    " 356: 'R-knee vs R-ankle relV horizontal',\n",
    " 357: 'L-shoulder vs L-elbow relV vertical',\n",
    " 358: 'L-shoulder vs L-elbow relV ignored',\n",
    " 359: 'L-shoulder vs L-elbow relV horizontal',\n",
    " 360: 'R-shoulder vs R-elbow relV vertical',\n",
    " 361: 'R-shoulder vs R-elbow relV ignored',\n",
    " 362: 'R-shoulder vs R-elbow relV horizontal',\n",
    " 363: 'L-elbow vs L-wrist relV vertical',\n",
    " 364: 'L-elbow vs L-wrist relV ignored',\n",
    " 365: 'L-elbow vs L-wrist relV horizontal',\n",
    " 366: 'R-elbow vs R-wrist relV vertical',\n",
    " 367: 'R-elbow vs R-wrist relV ignored',\n",
    " 368: 'R-elbow vs R-wrist relV horizontal',\n",
    " 369: 'pelvis vs L-shoulder relV vertical',\n",
    " 370: 'pelvis vs L-shoulder relV ignored',\n",
    " 371: 'pelvis vs L-shoulder relV horizontal',\n",
    " 372: 'pelvis vs R-shoulder relV vertical',\n",
    " 373: 'pelvis vs R-shoulder relV ignored',\n",
    " 374: 'pelvis vs R-shoulder relV horizontal',\n",
    " 375: 'pelvis vs neck relV vertical',\n",
    " 376: 'pelvis vs neck relV ignored',\n",
    " 377: 'pelvis vs neck relV horizontal',\n",
    " 378: 'L-hand vs R-hand relV vertical',\n",
    " 379: 'L-hand vs R-hand relV ignored',\n",
    " 380: 'L-hand vs R-hand relV horizontal',\n",
    " 381: 'L-foot vs R-foot relV vertical',\n",
    " 382: 'L-foot vs R-foot relV ignored',\n",
    " 383: 'L-foot vs R-foot relV horizontal',\n",
    " 384: 'L-knee ground on the ground',\n",
    " 385: 'L-knee ground ground-ignored',\n",
    " 386: 'R-knee ground on the ground',\n",
    " 387: 'R-knee ground ground-ignored',\n",
    " 388: 'L-foot ground on the ground',\n",
    " 389: 'L-foot ground ground-ignored',\n",
    " 390: 'R-foot ground on the ground',\n",
    " 391: 'R-foot ground ground-ignored'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a3baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "torch.set_printoptions(threshold=float('inf'))\n",
    "\n",
    "\"\"\"\n",
    "- Q1. code_prompt_1: Identify which joint states can be affected by the editing instruction.\n",
    "- Q2. frame_prompt_1: Use the joint states to determine which temporal segment should be edited.\n",
    "- Q3. code_prompt_2: Decide how to edit the code sequence of length p_length.\n",
    "- Q4. frame_prompt_2: Determine the frame range to edit.\n",
    "\n",
    "- Find the joint states that are mentioned in common in Q1 and Q2.\n",
    "- Based on those joint states, decide how to edit the code for Q3.\n",
    "- Decide which frame range to edit.\n",
    "\"\"\"\n",
    "\n",
    "for idx in range(1, len(editing_scenario) + 1):\n",
    "    save_prompt_dir = pjoin(save_dir, f'prompt/{sample_ids[idx-1]}')\n",
    "    os.makedirs(save_prompt_dir, exist_ok=True)\n",
    "    p_code = int_indices[idx-1].numpy()\n",
    "    p_length = motion_lens[idx-1]\n",
    "    p_details = editing_scenario[idx][\"text\"]\n",
    "    p_edit = editing_scenario[idx][\"scenario\"]\n",
    "    \n",
    "    frame_prompt_1 = f\"\"\"\n",
    "\n",
    "    Motion is represented by a set of joint states, defined as follows:\n",
    "    Table 1 Joint State Meanings (Key: Joint State Index, Value: Joint State Meaning): {p_table1}\n",
    "    Given the edit instruction: {p_edit}\n",
    "    Return a semi-colon separated sequence of the ids of the joint states you will need to examine\n",
    "    in order to determine the starting and ending frame of a motion sequence that will be affected\n",
    "    by the edit instruction.\n",
    "    Format example: 0;1;5;9. Do not reply anything else.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    frame_prompt_2 = f\"\"\"\n",
    "\n",
    "    You will be provided with a text description of the motion, a motion code sequence and a motion\n",
    "    edit instruction. You are be required to determine the starting and ending frame of the sequence\n",
    "    that will be affected by the edit. Here is what you need to know about the encoding of the motion\n",
    "    sequences:\n",
    "    The motion is represented a number of time frames, each time frame contains a set of joint states,\n",
    "    each joint state contains a code value. The definitions are:\n",
    "    Table 1 Joint State Meanings (Key: Joint State Index, Value: Joint State Meaning): {p_table1}\n",
    "    Table 2 Code Meaning (Key: Code ID, Value: Code Meaning): {p_table2}\n",
    "    Rules: smaller angles indicates more bending.\n",
    "    The motion code sequence is: {{p_code}}\n",
    "    The total number of time frames is {p_length}\n",
    "    The text description is: {p_details}\n",
    "    The edit instruction is: {p_edit}\n",
    "    Return the starting index and ending index of the segment that is affected by the edit, separated\n",
    "    by semi-colon, if the edit affects the overall movement, select the entire sequence. Format\n",
    "    example: 0;19. Do not reply anything else.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    code_prompt_1 = f\"\"\"\n",
    "\n",
    "    Motion is represented by a set of joint states, defined as follows:\n",
    "    Table 1 Joint State Meanings (Key: Joint State Index, Value: Joint State Meaning): {p_table1}\n",
    "    Given the edit instruction: {p_edit}\n",
    "    Return a semi-colon separated sequence of the ids of the joint states you may be affected by the\n",
    "    edit instruction. Format example: 0;1;5;9. Do not reply anything else.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    code_prompt_2 = f\"\"\"\n",
    "\n",
    "    You will be provided with a text description of the motion, a motion code sequence for a given\n",
    "    joint state and a motion edit instruction. You will be required to determine how to modify the\n",
    "    codes within the provided sequence accordingly.\n",
    "    Here is what you need to know about the encoding of the motion sequences: The motion is\n",
    "    represented as a list of joint states of length T, T is the number time frames. Each joint\n",
    "    state contains a code value. The usable codes are defined as follows:\n",
    "    Table 1 Usable Code Meaning (Key: Code ID, Value: Code Meaning): {p_table2}\n",
    "    Rules: smaller angles indicates more bending.\n",
    "    You are given this motion code sequence for the joint state {{joint_state}}, it has already been sliced\n",
    "    to keep only the segment you will need to edit: {{p_code}}.\n",
    "    The text description of the overall motion sequence is: {p_details}.\n",
    "    The edit instruction is: {p_edit}\n",
    "    Return the edited motion only as a sequence of integer code ids of length {p_length} separated by\n",
    "    semi-colons, only use code ids in the provided table. If no edit needs to be made, return the\n",
    "    original sequence. Format example: 1;2;3;4. Do not reply anything else. No explanation needed.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    sample_data = {\n",
    "        \"frame_prompt_1\": frame_prompt_1,\n",
    "        \"frame_prompt_2\": frame_prompt_2,\n",
    "        \"code_prompt_1\": code_prompt_1,\n",
    "        \"code_prompt_2\": code_prompt_2\n",
    "    }\n",
    "\n",
    "    for file_name, item in sample_data.items():\n",
    "        file_path = pjoin(save_prompt_dir, file_name + '.txt')\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f010dc3",
   "metadata": {},
   "source": [
    "# Get Reply From ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af2ce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from os.path import join as pjoin\n",
    "import sys\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from utils.codebook import group_id_to_full_group_name\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "def wait(interval=15):\n",
    "    tqdm.write(f\"Await {interval} seconds to avoid rate limit...\")\n",
    "    time.sleep(interval)\n",
    "    tqdm.write(\"Resuming...\")\n",
    "\n",
    "def parse_wait_interval(error_message: str) -> int:\n",
    "    m = re.search(r'in\\s+\"?([\\d\\.]+)\\s*(ms|s)\"?', error_message)\n",
    "    if m:\n",
    "        value = float(m.group(1))   \n",
    "        unit = m.group(2)         \n",
    "\n",
    "        if unit == 'ms':\n",
    "            seconds = value / 1000.0\n",
    "        else:  # 's'\n",
    "            seconds = value\n",
    "    else:\n",
    "        seconds = 20.0\n",
    "    \n",
    "    return float(seconds)\n",
    "    \n",
    "\n",
    "def kh2index(k_hot_array: np.ndarray):\n",
    "    \"\"\"\n",
    "    k_hot_array: (T, D) — 2D array of k-hot vectors.\n",
    "    Returns: (T, K) — indices of 1s.\n",
    "    \"\"\"\n",
    "    k = int(k_hot_array.sum(axis=-1)[0])\n",
    "    indices = np.argsort(k_hot_array, axis=-1)[:, -k:]\n",
    "\n",
    "    sorted_indices = np.sort(indices, axis=-1)\n",
    "    return sorted_indices\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"your api key here\",\n",
    ")\n",
    "\n",
    "from os.path import join as pjoin\n",
    "import datetime\n",
    "time_str = None\n",
    "\n",
    "if time_str == None:\n",
    "    time_str = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "dateid = timestamp\n",
    "prompt_dir = f'./motion_editing_result/{dateid}/prompt'\n",
    "save_reply_dir = f'./motion_editing_result/{dateid}/reply/{time_str}'\n",
    "code_dir = f'./motion_editing_result/{dateid}/gt/codes'\n",
    "model = \"gpt-5\"\n",
    "max_waiting_interval = 600  # seconds\n",
    "max_tol_pose_code_num = 40\n",
    "n_max_retry = 3\n",
    "\n",
    "name_list = target_file_list\n",
    "# \n",
    "print(\"total samples:\", len(name_list))\n",
    "os.makedirs(save_reply_dir, exist_ok=True)\n",
    "ban_list = []\n",
    "\n",
    "##########################\n",
    "for sample_id in tqdm(name_list):\n",
    "    tqdm.write(f\"Processing sample_id: {sample_id}\", file=sys.stderr)\n",
    "\n",
    "    if sample_id in ban_list:\n",
    "        tqdm.write(f\"sample_id:{sample_id} is in ban list, skip.\", file=sys.stderr)\n",
    "        continue\n",
    "\n",
    "    n_retry = 0\n",
    "    prompt_contents = []\n",
    "    answers = {}\n",
    "    skip_sample = False\n",
    "    prompt_names = ['code_prompt_1', 'code_prompt_2', 'frame_prompt_1', 'frame_prompt_2']\n",
    "    \n",
    "    if os.path.exists(pjoin(save_reply_dir, sample_id)):\n",
    "        tqdm.write(f\"found existing reply, skip:{sample_id}\", file=sys.stderr)\n",
    "        continue\n",
    "\n",
    "    # load prompt and reply template\n",
    "    for prompt_name in prompt_names:\n",
    "        file_path = pjoin(prompt_dir, sample_id, f'{prompt_name}.txt')\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            prompt = f.read()\n",
    "\n",
    "        prompt_contents.append(prompt)\n",
    "        answers[f\"{prompt_name}_reply\"] = []\n",
    "\n",
    "    # Q1. Joint states affected by the edit instruction\n",
    "    tqdm.write(\"Q1 processing...\", file=sys.stderr)\n",
    "    while True:\n",
    "        try:\n",
    "            res1 = client.responses.create(\n",
    "            model=model,\n",
    "            instructions=\"You are a motion-editing assistant. Follow the instructions written in the input text exactly and only return the requested output format\",\n",
    "            input=f\"{prompt_contents[0]}\",\n",
    "            store=True            \n",
    "            )\n",
    "\n",
    "            reply_joint_states = res1.output_text\n",
    "\n",
    "            joint_states = [int(e) for e in list(reply_joint_states.split(';'))]\n",
    "\n",
    "            if len(joint_states) > max_tol_pose_code_num:\n",
    "                tqdm.write(\"model tries to return too many joint states, retry...\", file=sys.stderr)\n",
    "                \n",
    "                n_retry += 1\n",
    "                \n",
    "                if n_retry >= n_max_retry:\n",
    "                    tqdm.write(f\"exceed max retry limit({n_max_retry}), sample_id:{sample_id}\", file=sys.stderr)\n",
    "                    skip_sample = True\n",
    "                    break\n",
    "                \n",
    "                continue\n",
    "\n",
    "            answers['code_prompt_1_reply'] = joint_states\n",
    "            break\n",
    "        except Exception as e:\n",
    "            tqdm.write(str(e), file=sys.stderr)\n",
    "            interval = parse_wait_interval(str(e))\n",
    "            interval = max(max_waiting_interval, interval * 5 + 5)\n",
    "            tqdm.write(f\"Error processing sample_id {sample_id} in Q1. will be retried after {interval}sec\", file=sys.stderr)\n",
    "            wait(interval=interval)\n",
    "            continue\n",
    "    \n",
    "    if skip_sample:\n",
    "        tqdm.write(f\"Skipping sample_id:{sample_id}\", file=sys.stderr)\n",
    "        continue\n",
    "    \n",
    "    tqdm.write(\"Q1 done\", file=sys.stderr)\n",
    "    tqdm.write(\"Q2 processing...\", file=sys.stderr)\n",
    "\n",
    "    progress_idx = 0\n",
    "    # Q2. \n",
    "    while True:\n",
    "        try:\n",
    "            code_file_path = pjoin(code_dir, f'{sample_id}.npy')\n",
    "            p_code = np.load(code_file_path)\n",
    "            int_code = kh2index(p_code)\n",
    "\n",
    "            # joint state에 해당하는 p_code만 가져오기\n",
    "            int_code_selected = int_code[:, joint_states].T\n",
    "\n",
    "            for id in range(progress_idx, len(joint_states)):\n",
    "                temp = prompt_contents[1]\n",
    "                joint_state = group_id_to_full_group_name[joint_states[id]]\n",
    "                selected_codes = int_code_selected.tolist()[id]\n",
    "                new_prompt_content = temp.replace(\"{joint_state}\", str(joint_state)).replace(\"{p_code}\", str(selected_codes))\n",
    "                \n",
    "                res2 = client.responses.create(\n",
    "                model=model,\n",
    "                instructions=\"You are a motion-editing assistant. Follow the instructions written in the input text exactly and only return the requested output format\",\n",
    "                input=f\"{new_prompt_content}\",\n",
    "                previous_response_id=res1.id\n",
    "                )\n",
    "                answers['code_prompt_2_reply'].append([int(e) for e in list(res2.output_text.split(';'))])\n",
    "                progress_idx += 1\n",
    "            break\n",
    "        except Exception as e:\n",
    "            tqdm.write(str(e), file=sys.stderr)\n",
    "            interval = parse_wait_interval(str(e))\n",
    "            p_progress = (progress_idx / len(joint_states)) * 100\n",
    "            interval = max(max_waiting_interval, (interval * len(joint_states) + 5))\n",
    "            tqdm.write(f\"Error processing sample_id {sample_id} in Q2(progress:{p_progress:.2f}%). will be retried after {interval}sec\", file=sys.stderr)\n",
    "            wait(interval=interval)\n",
    "            continue\n",
    "\n",
    "    tqdm.write(\"Q2 done\", file=sys.stderr)\n",
    "    tqdm.write(\"Q3 processing...\", file=sys.stderr)\n",
    "\n",
    "    # Q3.\n",
    "    while True:\n",
    "        try:\n",
    "            res3 = client.responses.create(\n",
    "                model=model,\n",
    "                instructions=\"You are a motion-editing assistant. Follow the instructions written in the input text exactly and only return the requested output format\",\n",
    "                input=f\"{prompt_contents[2]}\",\n",
    "                store=True,\n",
    "                previous_response_id=res1.id\n",
    "            )\n",
    "            joint_states_2 = [int(e) for e in list(res3.output_text.split(';'))]\n",
    "            answers['frame_prompt_1_reply'] = joint_states_2\n",
    "            break\n",
    "        except Exception as e:\n",
    "            tqdm.write(str(e), file=sys.stderr)\n",
    "            interval = parse_wait_interval(str(e))\n",
    "            interval = max(max_waiting_interval, interval * 5 + 5)\n",
    "            tqdm.write(f\"Error processing sample_id {sample_id} in Q3. will be retried after {interval}sec\", file=sys.stderr)\n",
    "            wait(interval=interval)\n",
    "            continue\n",
    "\n",
    "    tqdm.write(\"Q3 done\", file=sys.stderr)\n",
    "    tqdm.write(\"Q4 processing...\", file=sys.stderr)\n",
    "\n",
    "    # Q4.\n",
    "    progress_idx = 0\n",
    "    while True:\n",
    "        try:\n",
    "            for idx, p_codes in enumerate(answers['code_prompt_2_reply']):\n",
    "                \n",
    "                if idx < progress_idx:\n",
    "                    continue\n",
    "\n",
    "                temp = prompt_contents[3]\n",
    "                new_prompt = temp.replace(\"{p_code}\", str(p_codes))\n",
    "\n",
    "                res4 = client.responses.create(\n",
    "                model=model,\n",
    "                instructions=\"You are a motion-editing assistant. Follow the instructions written in the input text exactly and only return the requested output format\",\n",
    "                input=f\"{new_prompt}\",\n",
    "                previous_response_id=res3.id\n",
    "                )\n",
    "\n",
    "                answers['frame_prompt_2_reply'].append([int(e) for e in list(res4.output_text.split(';'))])\n",
    "                \n",
    "                progress_idx += 1\n",
    "            break\n",
    "        except Exception as e:\n",
    "            tqdm.write(str(e), file=sys.stderr)\n",
    "            interval = parse_wait_interval(str(e))\n",
    "            p_progress = (progress_idx / len(answers['code_prompt_2_reply'])) * 100\n",
    "            interval = max(max_waiting_interval, (interval * len(answers['code_prompt_2_reply']) + 5))\n",
    "            tqdm.write(f\"Error processing sample_id {sample_id} in Q4(progress:{p_progress:.2f}%). will be retried after {interval}sec\", file=sys.stderr)\n",
    "            wait(interval=interval)\n",
    "            continue\n",
    "\n",
    "    tqdm.write(\"Q4 done\", file=sys.stderr)\n",
    "    tqdm.write(\"Saving all answers...\", file=sys.stderr)\n",
    "    # Save all answers\n",
    "    reply_format = f\"\"\"\n",
    "\n",
    "    Q1: Return a semi-colon separated sequence of the ids of the joint states you may be affected by the edit instruction.\n",
    "    A1: {answers['code_prompt_1_reply']}\n",
    "\n",
    "    Q2: Return the edited motion only as a sequence of integer code ids of length 49 separated by semi-colons, only use code ids in the provided table.\n",
    "    A2: {answers['code_prompt_2_reply']}\n",
    "\n",
    "    Q3: Return a semi-colon separated sequence of the ids of the joint states you will need to examine in order to determine the starting and ending frame of a motion sequence that will be affected by the edit instruction.\n",
    "    A3: {answers['frame_prompt_1_reply']}\n",
    "\n",
    "    Q4: Return the starting index and ending index of the segment that is affected by the edit, separated by semi-colon, if the edit affects the overall movement, select the entire sequence.\n",
    "    A4: {answers['frame_prompt_2_reply']}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    file_dir = pjoin(save_reply_dir, sample_id)\n",
    "    os.makedirs(file_dir, exist_ok=True)\n",
    "    file_path = pjoin(file_dir, 'reply.txt')\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(reply_format)\n",
    "\n",
    "    tqdm.write(f\"Finished sample_id:{sample_id}\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f57170",
   "metadata": {},
   "source": [
    "# Load Reply Data With Completed Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502800a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from os.path import join as pjoin\n",
    "import json\n",
    "import ast\n",
    "date = timestamp\n",
    "time_stamp = time_str\n",
    "reply_dir = f'./motion_editing_result/{date}/reply/{time_stamp}'\n",
    "cached_dir = f'./motion_editing_result/{date}/gt'\n",
    "\n",
    "def parse_reply(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    matches = re.findall(r'A\\d:\\s*(.*?)(?=\\n\\s*Q|\\Z)', text, re.DOTALL)\n",
    "\n",
    "    if len(matches) == 4:\n",
    "        a1_str = matches[0].strip()\n",
    "        a2_str = matches[1].strip()\n",
    "        a3_str = matches[2].strip()\n",
    "        a4_str = matches[3].strip()\n",
    "\n",
    "        try:\n",
    "            A1 = json.loads(a1_str)\n",
    "            A2 = json.loads(a2_str)\n",
    "            A3 = json.loads(a3_str)\n",
    "            A4 = json.loads(a4_str)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error: Failed to convert the extracted string into a Python list. - {e}\")\n",
    "            print(\"--- Original string ---\")\n",
    "            print(f\"A1_str: {a1_str}\")\n",
    "            print(f\"A2_str: {a2_str}\")\n",
    "            print(f\"A3_str: {a3_str}\")\n",
    "            print(f\"A4_str: {a4_str}\")\n",
    "    else:\n",
    "        print(\"Error: Could not find all answers for A1, A2, A3, and A4 in the file.\")\n",
    "    return A1, A2, A3, A4\n",
    "\n",
    "def parse_edit_text(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    pattern = r\"Given the edit instruction:\\s*(.+?)\\s*(?:\\n|$)\"\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        instruction = match.group(1)  # \"Make the movement look more energetic.\"\n",
    "    else:\n",
    "        print(\"No instruction found\")\n",
    "        raise Exception(\"No instruction found in the provided file.\")\n",
    "    \n",
    "    return instruction\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d31f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(reply_dir) and os.path.isdir(reply_dir):\n",
    "    sample_ids = [name for name in os.listdir(reply_dir) if os.path.isdir(pjoin(reply_dir, name))]\n",
    "\n",
    "print(sample_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a770d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index2kh(indices_array: np.ndarray, D: int) -> np.ndarray:\n",
    "    T = indices_array.shape[0]\n",
    "    k_hot_array = np.zeros((T, D), dtype=int)\n",
    "    row_indices = np.arange(T)[:, np.newaxis]\n",
    "    k_hot_array[row_indices, indices_array] = 1\n",
    "    \n",
    "    return k_hot_array\n",
    "\n",
    "def kh2index(k_hot_array: np.ndarray):\n",
    "    \"\"\"\n",
    "    k_hot_array: (T, D) — 2D array of k-hot vectors.\n",
    "    Returns: (T, K) — indices of 1s.\n",
    "    \"\"\"\n",
    "\n",
    "    k = int(k_hot_array.sum(axis=-1)[0])\n",
    "    indices = np.argsort(k_hot_array, axis=-1)[:, -k:]\n",
    "    sorted_indices = np.sort(indices, axis=-1)\n",
    "    \n",
    "    return sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae3552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_motions = []\n",
    "feats_motions = []\n",
    "int_indices = []\n",
    "texts = []\n",
    "edit_texts = []\n",
    "edit_mode = 'gpt_edit'\n",
    "\n",
    "if edit_mode == 'gpt_edit':\n",
    "    prompt_dir = f'./motion_editing_result/{date}/prompt'\n",
    "\n",
    "for sample_id in sample_ids:\n",
    "    code_motion = np.load(pjoin(cached_dir, 'codes', f'{sample_id}.npy'))\n",
    "    pose = np.load(pjoin(cached_dir, 'npy_pose', f'{sample_id}.npy'))\n",
    "    coords = np.load(pjoin(cached_dir, 'npy_coords', f'{sample_id}.npy'))\n",
    "    txt_path = pjoin(cached_dir, 'texts', f'{sample_id}.txt')\n",
    "    with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read().strip()\n",
    "    texts.append(text)\n",
    "    \n",
    "    if edit_mode == 'gpt_edit':\n",
    "        edit_text = parse_edit_text(pjoin(prompt_dir, sample_id, 'frame_prompt_1.txt'))\n",
    "        edit_texts.append(edit_text)\n",
    "    \n",
    "    int_idx = kh2index(code_motion)\n",
    "    code_motions.append(code_motion)\n",
    "    int_indices.append(int_idx)\n",
    "    feats_motions.append(pose)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25aa4f6",
   "metadata": {},
   "source": [
    "# Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3ff937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import argparse\n",
    "\n",
    "checkpoint_dir = './pretrained/exp_pg_tokenizer'\n",
    "exp_name = checkpoint_dir.split('/')[-1]\n",
    "print(exp_name)\n",
    "\n",
    "config = pjoin(checkpoint_dir, 'arguments.yaml')\n",
    "with open(config, 'r') as f:\n",
    "    arg_dict = yaml.safe_load(f)\n",
    "\n",
    "args = argparse.Namespace(**arg_dict)\n",
    "\n",
    "ours = PoseGuidedTokenizer(\n",
    "                    args, \n",
    "                    args.nb_code,                      # nb_code\n",
    "                    args.code_dim,                    # code_dim\n",
    "                    args.output_emb_width,            # output_emb_width\n",
    "                    args.down_t,                      # down_t\n",
    "                    args.stride_t,                    # stride_t\n",
    "                    args.width,                       # width\n",
    "                    args.depth,                       # depth\n",
    "                    args.dilation_growth_rate,        # dilation_growth_rate\n",
    "                    args.vq_act,                      # activation\n",
    "                    args.vq_norm,                     # norm\n",
    "                    args.cfg_cla,                     # cfg_cla\n",
    "                    aggregate_mode=None,    # aggregate_mode\n",
    "                    num_quantizers=args.rvq_num_quantizers,\n",
    "                    shared_codebook=args.rvq_shared_codebook,\n",
    "                    quantize_dropout_prob=args.rvq_quantize_dropout_prob,\n",
    "                    quantize_dropout_cutoff_index=args.rvq_quantize_dropout_cutoff_index,\n",
    "                    rvq_nb_code=args.rvq_nb_code,\n",
    "                    mu=args.rvq_mu,\n",
    "                    resi_beta=args.rvq_resi_beta,\n",
    "                    quantizer_type=getattr(args, 'rvq_quantizer_type', 'hard'),\n",
    "                    params_soft_ent_loss=0.0,\n",
    "                    use_ema=(not getattr(args, 'unuse_ema', False)),\n",
    "                    init_method=getattr(args, 'rvq_init_method', 'enc'),  # 'enc', 'xavier', 'uniform',\n",
    ")\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "checkpoint_path = pjoin(checkpoint_dir, 'net_best_fid.pth')\n",
    "ckpt = torch.load(checkpoint_path, map_location='cpu')\n",
    "unit_length = 4\n",
    "\n",
    "if args.dataname == 'kit' : \n",
    "    args.nb_joints = 21\n",
    "    args.max_motion_len = 196\n",
    "else:\n",
    "    args.nb_joints = 22\n",
    "    args.max_motion_len = 196\n",
    "\n",
    "ours.load_state_dict(ckpt['net'], strict=True)\n",
    "print(f\"loaded iter:{ckpt['nb_iter']}\")\n",
    "\n",
    "if use_gpu:\n",
    "    ours.cuda()\n",
    "\n",
    "ours.eval()\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a266af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_motion_len =  196\n",
    "unit_length = 4\n",
    "\n",
    "def inv_transform(data, mean, std):\n",
    "    return data * std + mean\n",
    "\n",
    "def transform(data, mean, std):\n",
    "    return (data - mean) / std\n",
    "\n",
    "meta_dir = 'checkpoints/t2m/VQVAEV3_CB1024_CMT_H1024_NRES3/meta'\n",
    "mean = np.load(pjoin(meta_dir, 'mean.npy'))\n",
    "std = np.load(pjoin(meta_dir, 'std.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b9a34a",
   "metadata": {},
   "source": [
    "# Edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412807ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.codebook import *\n",
    "import torch\n",
    "full_cat_name_to_cat_id = {v: k for k, v in cat_id_to_full_cat_name.items()}\n",
    "\n",
    "edited_codes = []\n",
    "target_lens = []\n",
    "mot_downsampled_list = []\n",
    "edit_mode = 'gpt_edit' # or 'gpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3f2d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_custom(code_indices, target_cat_name, force_edit=True):\n",
    "    cat_id = full_cat_name_to_cat_id[target_cat_name]\n",
    "    group_id = cat_id_to_group_id[cat_id]\n",
    "    end, start = vq_to_range[group_id]\n",
    "    # code_indices.shape -> N, C\n",
    "    new_code_indices = code_indices.clone()\n",
    "\n",
    "    activated = torch.argmax(code_indices[:, start:end+1].float(), dim=1) # 상대적인 카테고리 순번\n",
    "    activated = start + activated\n",
    "\n",
    "    if force_edit:  # 전체 시간에 대하여 \n",
    "        new_code_indices[:, start:end+1] = 0\n",
    "        new_code_indices[:, cat_id] = 1\n",
    "        result_dict = {}\n",
    "\n",
    "        new_activated = torch.argmax(new_code_indices[:, start:end+1].float(), dim=1) # 상대적인 카테고리 순번\n",
    "        new_activated = start + new_activated\n",
    "        for i in range(activated.shape[0]):\n",
    "            result_dict[f\"frame_{i}(src -> tgt)\"] = (id_to_name[activated[i].item()], target_cat_name) \n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    return new_code_indices, result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313d71ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_edit_code_indices: a variable that indicates which codes need to be changed\n",
    "\n",
    "def edit_motion_code_from_reply(source_code, joint_indices, new_code_sequences, frame_ranges):\n",
    "    \n",
    "    # Create a copy to avoid modifying the original array in place.\n",
    "    modified_code = source_code.copy()\n",
    "\n",
    "    # Use zip to iterate over the three lists (joints, new codes, frame ranges) simultaneously.\n",
    "    for joint_idx, new_codes, frame_range in zip(joint_indices, new_code_sequences, frame_ranges):\n",
    "        \n",
    "        # Get the start and end frames of the segment to edit.\n",
    "        start_frame, end_frame = frame_range\n",
    "        \n",
    "        # To include end_frame, set the slicing range up to end_frame + 1.\n",
    "        target_slice = slice(start_frame, end_frame + 1)\n",
    "        \n",
    "        # Use slicing and indexing to select a specific joint and frame range,\n",
    "        # and overwrite it with the new code sequence.\n",
    "        # The length of new_codes must match the length of the sliced segment.\n",
    "        if len(new_codes) == (end_frame - start_frame + 1):\n",
    "            modified_code[target_slice, joint_idx] = new_codes\n",
    "        else:\n",
    "            print(f\"Warning: The code sequence length ({len(new_codes)}) for joint {joint_idx} \"\n",
    "                  f\"does not match the length of the frame range ({start_frame}-{end_frame}), so it is skipped.\")\n",
    "\n",
    "    return modified_code\n",
    "\n",
    "def edit_motion_code_from_reply_v2(source_code, joint_indices_1, joint_indices_2, new_code_sequences, frame_ranges):\n",
    "    \"\"\"\n",
    "    Assumptions:\n",
    "    - source_code.shape == (T, J)\n",
    "    - len(new_codes) >= T  (or at least >= end_frame + 1)\n",
    "    - frame_ranges is a list of (start_frame, end_frame) tuples\n",
    "    \"\"\"\n",
    "    modified_code = source_code.copy()\n",
    "    T = source_code.shape[0]\n",
    "\n",
    "    joint_indices = list(set(joint_indices_1) & set(joint_indices_2))\n",
    "    print(\"intersected joint indices:\", joint_indices)\n",
    "    \n",
    "    for joint_idx, new_codes, frame_range in zip(joint_indices, new_code_sequences, frame_ranges):\n",
    "        start_frame, end_frame = frame_range\n",
    "\n",
    "        # Clamp to valid array bounds\n",
    "        start = max(0, start_frame)\n",
    "        end = min(T - 1, end_frame)\n",
    "\n",
    "        if end < start:\n",
    "            print(f\"Warning: Invalid frame range ({start_frame}, {end_frame}), so it is skipped.\")\n",
    "            continue\n",
    "\n",
    "        if end >= len(new_codes):\n",
    "            print(\n",
    "                f\"Warning: For joint {joint_idx}, end_frame({end}) exceeds new_codes length ({len(new_codes)}), \"\n",
    "                f\"so it is adjusted to {len(new_codes)-1}.\"\n",
    "            )\n",
    "            end = len(new_codes) - 1\n",
    "            if end < start:\n",
    "                print(\n",
    "                    f\"Warning: The adjusted range ({start}, {end}) is invalid, so it is skipped.\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "        target_slice = slice(start, end + 1)\n",
    "\n",
    "        modified_code[target_slice, joint_idx] = new_codes[target_slice]\n",
    "\n",
    "    return modified_code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54606e68",
   "metadata": {},
   "source": [
    "### Edit Pose Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e00147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import device\n",
    "\n",
    "\n",
    "if edit_mode == 'custom_edit':\n",
    "    target_code_list = ['L-hand vs R-hand distance 1', 'L-elbow vs R-elbow distance 1', 'L-hand vs R-elbow distance 1', 'R-hand vs L-elbow distance 1']\n",
    "    for idx, id in enumerate(sample_ids):\n",
    "        print(f\"## id:{id} ##\")\n",
    "        \n",
    "        # data\n",
    "        mo_pose_codes = code_motions[idx] #\n",
    "        mo_pose_codes = torch.from_numpy(mo_pose_codes)\n",
    "\n",
    "        motion = feats_motions[idx]\n",
    "        motion = torch.from_numpy(motion)\n",
    "        \n",
    "        mo_len, cb_num = mo_pose_codes.shape\n",
    "\n",
    "        # edit: changes every frame as L-knee angle 10\n",
    "        temp = mo_pose_codes\n",
    "        for target_code in target_code_list:\n",
    "            temp, _ = edit_custom(temp, target_code, force_edit=True)\n",
    "        new_code_indices = temp\n",
    "        \n",
    "        target_len = (mo_len // unit_length) * unit_length\n",
    "        motion_downsampled = motion[:target_len,:].unsqueeze(0)\n",
    "        mot_downsampled_list.append(motion_downsampled)\n",
    "        \n",
    "        target_lens.append(target_len)\n",
    "        \n",
    "        if use_gpu:\n",
    "            new_code_indices = new_code_indices.cuda()\n",
    "\n",
    "        edited_codes.append(new_code_indices.float())\n",
    "        edit_texts.append(f\"Custom Edit:({str(target_code_list)})\")\n",
    "\n",
    "elif edit_mode == 'gpt_edit':\n",
    "    for idx, id in enumerate(sample_ids):\n",
    "        print(f\"## id:{id} ##\")\n",
    "\n",
    "        mo_pose_codes = code_motions[idx] #\n",
    "        mo_pose_codes = torch.from_numpy(mo_pose_codes)\n",
    "\n",
    "        motion = feats_motions[idx]\n",
    "        motion = torch.from_numpy(motion)\n",
    "        \n",
    "        mo_len, cb_num = mo_pose_codes.shape\n",
    "        \n",
    "        # edit from gpt reply\n",
    "        reply_file_path = pjoin(reply_dir, id, 'reply.txt')\n",
    "        a1, a2, a3, a4 = parse_reply(reply_file_path)\n",
    "        edited_code = edit_motion_code_from_reply_v2(int_indices[idx], a1, a3, a2, a4)\n",
    "\n",
    "        edited_kh_code = index2kh(edited_code, D=392)\n",
    "        target_len = (mo_len // unit_length)*unit_length\n",
    "        motion_downsampled = motion[:target_len,:].unsqueeze(0)\n",
    "        mot_downsampled_list.append(motion_downsampled)\n",
    "\n",
    "        target_lens.append(target_len)\n",
    "\n",
    "        _edited_kh_code = torch.from_numpy(edited_kh_code).float()\n",
    "\n",
    "        if use_gpu:\n",
    "            _edited_kh_code = _edited_kh_code.cuda()\n",
    "        edited_codes.append(_edited_kh_code)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69403a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_save_dir = pjoin(save_dir, 'gt', 'edit')\n",
    "edit_coord_dir = f\"{edit_save_dir}/{time_stamp}/{exp_name}/edit/{edit_mode}/npy_coords\"\n",
    "vis_save_dir = f\"{edit_save_dir}/{time_stamp}/{exp_name}/edit/{edit_mode}/gif\"\n",
    "\n",
    "if not os.path.exists(edit_coord_dir):\n",
    "    os.makedirs(edit_coord_dir)\n",
    "\n",
    "if not os.path.exists(vis_save_dir):\n",
    "    os.makedirs(vis_save_dir)\n",
    "\n",
    "for idx, id in enumerate(sample_ids):\n",
    "    print(f\"## id:{id} ##\")\n",
    "\n",
    "    save_path = f\"{vis_save_dir}/{id}.gif\"\n",
    "\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"Skip existing {save_path}\")\n",
    "        continue\n",
    "    \n",
    "    # target_len = target_lens[idx]\n",
    "    mo_pose_codes = edited_codes[idx].unsqueeze(0)\n",
    "    mot_downsampled = mot_downsampled_list[idx]\n",
    "    print(mo_pose_codes.shape)\n",
    "    print(mot_downsampled.shape)\n",
    "\n",
    "    pred_motion, *_ = ours(code_indices=mo_pose_codes.float(), motion=mot_downsampled.float(), drop_out_residual_quantization=True)\n",
    "        \n",
    "    pred_denorm = inv_transform(pred_motion.cpu().detach().numpy(), mean, std)\n",
    "    pred_xyz = recover_from_ric(torch.from_numpy(pred_denorm).float(), 22)\n",
    "    pred_xyz = pred_xyz.numpy()\n",
    "\n",
    "    np.save(pjoin(edit_coord_dir, f\"{id}.npy\"), pred_xyz.squeeze(0))\n",
    "\n",
    "    print(pred_xyz.shape)\n",
    "    \n",
    "    sentence = texts[idx]\n",
    "\n",
    "    plot_3d.draw_to_batch(pred_xyz, [sentence], [save_path], footer_text=f'Edit, edit_text:{edit_texts[idx]}', footer_fontsize=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_como (3.8.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
